# 本节课程
1. 添加item
2. 图片下载pipeline
	- 如何做？
	- 只需要将scrapy内置的ImagePipeline 添加到ITEM_PIPELINE就好了
	- (可以在scrapy源码中找到)
	1. 添加 scrapy.pipelines.images.ImagesPipeline
	2. 在settings中配置 item中的哪个字段 是要下载的img
	3. 在ssettings的同级创建 images 文件夹
	**这里的 IMAGES_URLS_FIELD 必须是一个 列表
       ```python
	   import os
	   ITEM_PIPELINES = {
	       'scrapy.pipelines.images.ImagesPipeline': 1
	   }
	   # 要下载的图片 的 名字
	   IMAGES_URLS_FIELD = 'front_img_url'
	   project_dir = os.path.dirname(os.path.abspath(__file__))
	   # 要把图片存储的路径
	   IMAGES_STORE = os.path.join(project_dir, 'images')
	   # 过滤图片 图片最小宽度， 最小高度
	   # IMAGES_MIN_WIDTH = 100
	   # IMAGES_MIN_HEIGHT = 100

```
	


3. 如何获取到 imagespipeline 中图片存储的路径？
   - 我们需要重写一下 scrapy的ImagesPipeline
   ```python
   from scrapy.pipelines.images import ImagesPipeline

   class ArtileImagePipeline(ImagesPipeline):
    # 路径就存储在 results 里面
    # 如果之前下载了图片我么需要 把图片删除掉！！ scrapy 默认会查询， 如果有就不下载了
    # 使用这个pipeline 把它添加到settings 里面
    def item_completed(self, results, item, info):
        # results <class 'list'>: [(True, {'url': 'http://jbcdn2.b0.upaiyun.com/2012/04/vim-logo.png', 'path': 'full/4c6abd763d27eeeb4c7e7665f213388ec74df623.jpg', 'checksum': '43b702dae610119a059895537c489e1a'})]
        # 路径 取 列表第二个字典里面的 path
        for _,value in results:
            front_img_local_path = value['path']
        item['front_img_local_path'] = front_img_local_path
        # 一定要把item 返回回去
        return item

 ```

4. 处理url_md5_id 
   - 在settings同级目录下创建utils文件夹 创建common.py
   - 在spider.py 中引用就行
   ```python
   # -*- coding: utf-8 -*-
	import hashlib

	def get_md5(url):
	    # 判断url 是不是unicode 如果是就转码
	    if isinstance(url, str):
	        url = url.encode('utf-8')

	    m = hashlib.md5()
	    m.update(url)
	    return m.hexdigest()

```

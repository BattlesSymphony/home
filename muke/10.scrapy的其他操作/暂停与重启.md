# 我们要提供一个目录 让scrapy暂停的时候把目录放到JOBDIR下面
**不同 spider 暂停重启不能共用一个目录，
不同的spider 要设置不同的目录
```cmd
# 1. 命令行指定参数
scrapy crawl lagou -s JOBDIR=job/info/001
```
```python
# 2. settings.py文件下设置
JOBDIR="job/info/001"

# 3. 在Spider 下custom_settings设置
# 虽然可以设置， 但是在pycharm里面是无法发送Ctrl save命令的
# 所以尽量使用命令行，第一种方法
custom_settings ={ 
	JOBDIR="job/info/001"
}
```

```cmd
# 执行完命令行后 按一次Ctrl+C 就终止了scrapy
# 有些后续的没处理需要处理处理 我们等待 命令行结束

# 如何重新启动 还是和原来的命令一模一样
scrapy crawl lagou -s JOBDIR=job/info/001
```

## 如果想要从头开始爬怎么办？
我们只需要重新指定一个目录就好
```
scrapy crawl lagou -s JOBDIR=job/info/002
```
### 反爬手段
1. 使用fake_useragent 创建User-Agent 池
2. 使用 代理ip
3. 云打码平台
4. scrapy的配置
```python
# 设置为False 之后就会禁用
COOKIES_ENABLED = False

# 自动限速扩展
# https://scrapy-chs.readthedocs.io/zh_CN/0.22/topics/autothrottle.html
```

5. 不同的spider 配置不同的 setting值
**知乎不能禁用cookies， 伯乐在线可以禁用cookies，不同的spider如何设置不同的setting？

scrapy的源码里面
scrapy.spider.__init__ 里面有一个 custom_settings = None
我们只需要在写每个爬虫的时候覆盖custom_settings就好了

```python 
# settings.py
# Disable cookies (enabled by default)
COOKIES_ENABLED = False


# spiders/zhihu.py
class ZhihuSpider(scrapy.Spider):
    name = 'zhihu'
    allowed_domains = ['zhihu.com']
    start_urls = ['https://www.zhihu.com/index']
    custom_settings = {
       'COOKIES_ENABLED': True,
    }
```